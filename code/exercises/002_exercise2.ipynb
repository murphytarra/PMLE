{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise: Explore, Evaluate, and Package Your MNIST Library\n",
    "\n",
    "##¬†What's the Plan?\n",
    "Welcome to the next challenge! In this exercise, you‚Äôll refine your MNIST library, test different machine learning models, evaluate their performance using multiple metrics, and make your library user-friendly. The easiest-to-use library wins **chocolate**! üç´\n",
    "\n",
    "---\n",
    "\n",
    "## **Goals**\n",
    "1. **Explore Models**: Test different supervised learning models to determine the best one for the MNIST dataset.\n",
    "2. **Evaluate Metrics**: Use accuracy, precision, recall, F1-score, and confusion matrices to evaluate model performance.\n",
    "3. **Make It User-Friendly**: Package your library so others can use it easily.\n",
    "4. **Upload to GitHub**: Share your work with the world! :) \n",
    "\n",
    "---\n",
    "\n",
    "## **Instructions**\n",
    "\n",
    "### **Step 1: Test Different Models**\n",
    "- Use your library to:\n",
    "  - Load the MNIST dataset.\n",
    "  - Normalize the data to `[0, 1]`.\n",
    "  - Split the data into training, validation, and test sets.\n",
    "- Test the following models from Scikit-learn:\n",
    "  - **Logistic Regression**\n",
    "  - **Random Forest**\n",
    "  - **Support Vector Machines (SVM)**\n",
    "  - **k-Nearest Neighbors (k-NN)**\n",
    "\n",
    "Test each model with different metrics, such as the confusion matrix, F1-score or MSE. \n",
    "\n",
    "Upload your well documented notebook to your MNIST repo and the one I find easiest to use wins some delightful chocolate!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
